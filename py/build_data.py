#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è¯´æ•°æ®æ„å»ºè„šæœ¬
æ ¹æ® config.toml ç”Ÿæˆç½‘ç«™æ‰€éœ€çš„ JSON æ•°æ®æ–‡ä»¶
"""

import os
import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Any
import time

import tomllib  # Python 3.11+

class NovelDataBuilder:
    def __init__(self, config_path: str = "config.toml"):
        self.config_path = config_path
        self.config = None
        self.chinese_content = {}  # å…¨å±€ä¸­æ–‡å†…å®¹æ˜ å°„
        self.data_dir = Path("data")
        
        # ç¡®ä¿ data ç›®å½•å­˜åœ¨
        self.data_dir.mkdir(exist_ok=True)
        
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'rb') as f:
                self.config = tomllib.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {self.config_path}")
        except FileNotFoundError:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ è§£æé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
    
    def parse_chinese_content(self, file_path: str) -> Dict[int, str]:
        """è§£æä¸­æ–‡å¯¹ç…§æ–‡ä»¶"""
        chinese_map = {}
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # åŒ¹é…æ ¼å¼: æ–‡æœ¬å†…å®¹ [[æ•°å­—]]
                match = re.match(r'^(.*?)\s*\[\[(\d+)\]\]$', line)
                if match:
                    text = match.group(1).strip()
                    sentence_id = int(match.group(2))
                    chinese_map[sentence_id] = text
            
            print(f"âœ… è§£æä¸­æ–‡å†…å®¹: {len(chinese_map)} æ¡è¯­å¥")
            return chinese_map
            
        except FileNotFoundError:
            print(f"âŒ ä¸­æ–‡æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return {}
        except Exception as e:
            print(f"âŒ è§£æä¸­æ–‡æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def parse_english_chapter(self, file_path: str) -> List[Dict[str, Any]]:
        """è§£æè‹±æ–‡ç« èŠ‚æ–‡ä»¶"""
        sentences = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # åŒ¹é…æ ¼å¼: æ–‡æœ¬å†…å®¹ [[æ•°å­— è¯´è¯è€… æƒ…ç»ª]]
                match = re.match(r'^(.*?)\s*\[\[(\d+)\s+([^\s]+)\s+([^\]]+)\]\]$', line)
                if match:
                    english_text = match.group(1).strip()
                    sentence_id = int(match.group(2))
                    speaker = match.group(3)
                    emotion = match.group(4)
                    
                    sentence = {
                        "id": sentence_id,
                        "en": english_text,
                        "speaker": speaker,
                        "emotion": emotion
                    }
                    sentences.append(sentence)
            
            print(f"âœ… è§£æè‹±æ–‡ç« èŠ‚ {os.path.basename(file_path)}: {len(sentences)} æ¡è¯­å¥")
            return sentences
            
        except FileNotFoundError:
            print(f"âŒ è‹±æ–‡ç« èŠ‚æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        except Exception as e:
            print(f"âŒ è§£æè‹±æ–‡ç« èŠ‚å¤±è´¥: {e}")
            return []
    
    def check_local_audio_exists(self, local_audio_path: Path, chapter_id: str, sentence_id: int) -> bool:
        """æ£€æŸ¥æœ¬åœ°éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        audio_file = local_audio_path / chapter_id / f"{sentence_id}.wav"
        return audio_file.exists()
    
    def check_chapter_audio(self, local_audio_path: Path, chapter_id: str, sentences: List[Dict]) -> List[int]:
        """æ£€æŸ¥ä¸€ä¸ªç« èŠ‚çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶"""
        available_audio = []
        
        # æ£€æŸ¥ç« èŠ‚ç›®å½•æ˜¯å¦å­˜åœ¨
        chapter_audio_dir = local_audio_path / chapter_id
        if not chapter_audio_dir.exists():
            print(f"  âš ï¸  éŸ³é¢‘ç›®å½•ä¸å­˜åœ¨: {chapter_audio_dir}")
            return available_audio
        
        # é€ä¸ªæ£€æŸ¥æ¯ä¸ªè¯­å¥çš„éŸ³é¢‘æ–‡ä»¶
        for sentence in sentences:
            sentence_id = sentence["id"]
            if self.check_local_audio_exists(local_audio_path, chapter_id, sentence_id):
                available_audio.append(sentence_id)
        
        print(f"  ğŸ“» ç« èŠ‚ {chapter_id}: {len(available_audio)}/{len(sentences)} æ¡è¯­å¥æœ‰éŸ³é¢‘")
        return available_audio
    
    def build_book_data(self, book_id: str, book_config: Dict) -> tuple:
        """æ„å»ºå•æœ¬ä¹¦çš„æ•°æ®"""
        print(f"\nğŸ“š å¤„ç†ä¹¦ç±: {book_id} - {book_config.get('title', book_id)}")
        
        # åŠ è½½ä¸­æ–‡å¯¹ç…§å†…å®¹
        cn_file = book_config.get('cn')
        if cn_file:
            chinese_content = self.parse_chinese_content(cn_file)
        else:
            print("âš ï¸  æ²¡æœ‰é…ç½®ä¸­æ–‡å¯¹ç…§æ–‡ä»¶")
            chinese_content = {}
        
        # ä¹¦ç±æ•°æ®ç»“æ„
        book_data = {
            "bookId": book_id,
            "bookTitle": book_config.get('title', book_id),
            "chapters": {}
        }
        
        # éŸ³é¢‘æ•°æ®ç»“æ„
        audio_data = {
            "bookId": book_id,
            "audioBaseUrl": self.config.get('url', '') + book_config.get('audio', ''),
            "availability": {}
        }
        
        # ç« èŠ‚ä¿¡æ¯ï¼ˆç”¨äºä¸»ç´¢å¼•ï¼‰
        chapters_info = []
        
        # å¤„ç†ç« èŠ‚
        chap_config = book_config.get('chap', {})
        
        # è·å–æœ¬åœ°éŸ³é¢‘ç›®å½•è·¯å¾„
        local_audio_path = Path(book_config.get('audio', ''))
        if not local_audio_path.exists():
            print(f"âš ï¸  æœ¬åœ°éŸ³é¢‘ç›®å½•ä¸å­˜åœ¨: {local_audio_path}")
            print(f"    å°†åˆ›å»ºç©ºçš„éŸ³é¢‘å¯ç”¨æ€§æ•°æ®")
        
        for chap_num, chap_info in chap_config.items():
            chapter_id = str(chap_num).zfill(4)  # æ ¼å¼åŒ–ä¸º 0001, 0002 ç­‰
            
            print(f"  ğŸ“– å¤„ç†ç« èŠ‚ {chapter_id}: {chap_info.get('title', '')}")
            
            # è§£æè‹±æ–‡ç« èŠ‚
            en_file = chap_info.get('en')
            if not en_file:
                print(f"    âš ï¸  ç« èŠ‚ {chapter_id} æ²¡æœ‰é…ç½®è‹±æ–‡æ–‡ä»¶")
                continue
            
            sentences = self.parse_english_chapter(en_file)
            if not sentences:
                print(f"    âš ï¸  ç« èŠ‚ {chapter_id} æ²¡æœ‰è§£æåˆ°è¯­å¥")
                continue
            
            # æ·»åŠ ä¸­æ–‡å†…å®¹
            for sentence in sentences:
                sentence_id = sentence["id"]
                sentence["cn"] = chinese_content.get(sentence_id, "")
            
            # æ£€æŸ¥æœ¬åœ°éŸ³é¢‘å¯ç”¨æ€§
            print(f"  ğŸ” æ£€æŸ¥ç« èŠ‚ {chapter_id} çš„æœ¬åœ°éŸ³é¢‘æ–‡ä»¶...")
            available_audio = self.check_chapter_audio(local_audio_path, chapter_id, sentences)
            
            # ä¿å­˜æ•°æ®
            book_data["chapters"][chapter_id] = sentences
            audio_data["availability"][chapter_id] = available_audio
            
            # æ·»åŠ åˆ°ç« èŠ‚ä¿¡æ¯
            chapters_info.append({
                "id": chapter_id,
                "title": chap_info.get('title', f'ç¬¬{chap_num}ç« ')
            })
        
        return book_data, audio_data, chapters_info
    
    def build_all_data(self):
        """æ„å»ºæ‰€æœ‰æ•°æ®"""
        print("ğŸš€ å¼€å§‹æ„å»ºå°è¯´æ•°æ®...")
        
        # ä¸»ç´¢å¼•æ•°æ®
        novels_index = []
        
        # å¤„ç†æ¯æœ¬ä¹¦
        novels_config = self.config.get('novels', {})
        for book_id, book_config in novels_config.items():
            book_data, audio_data, chapters_info = self.build_book_data(book_id, book_config)
            
            # ä¿å­˜ä¹¦ç±å†…å®¹æ–‡ä»¶
            book_file = self.data_dir / f"{book_id}.json"
            with open(book_file, 'w', encoding='utf-8') as f:
                json.dump(book_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… ä¿å­˜ä¹¦ç±å†…å®¹: {book_file}")
            
            # ä¿å­˜éŸ³é¢‘æ•°æ®æ–‡ä»¶
            audio_file = self.data_dir / f"{book_id}_audio.json"
            with open(audio_file, 'w', encoding='utf-8') as f:
                json.dump(audio_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… ä¿å­˜éŸ³é¢‘æ•°æ®: {audio_file}")
            
            # æ·»åŠ åˆ°ä¸»ç´¢å¼•
            novels_index.append({
                "id": book_id,
                "title": book_config.get('title', book_id),
                "chapters": chapters_info
            })
        
        # ä¿å­˜ä¸»ç´¢å¼•æ–‡ä»¶
        index_file = self.data_dir / "novels.json"
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(novels_index, f, ensure_ascii=False, indent=2)
        print(f"âœ… ä¿å­˜ä¸»ç´¢å¼•: {index_file}")
        
        print(f"\nğŸ‰ æ•°æ®æ„å»ºå®Œæˆ! å…±å¤„ç† {len(novels_index)} æœ¬ä¹¦")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_chapters = sum(len(book["chapters"]) for book in novels_index)
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - ä¹¦ç±æ•°é‡: {len(novels_index)}")
        print(f"   - ç« èŠ‚æ€»æ•°: {total_chapters}")
        print(f"   - ç”Ÿæˆæ–‡ä»¶: {len(os.listdir(self.data_dir))} ä¸ª")
    
    def run(self):
        """è¿è¡Œæ„å»ºè¿‡ç¨‹"""
        start_time = time.time()
        
        print("=" * 50)
        print("ğŸ“– å°è¯´æ•°æ®æ„å»ºå·¥å…·")
        print("=" * 50)
        
        # åŠ è½½é…ç½®
        self.load_config()
        
        # æ„å»ºæ•°æ®
        self.build_all_data()
        
        end_time = time.time()
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")
        print("=" * 50)


def main():
    """ä¸»å‡½æ•°"""
    builder = NovelDataBuilder()
    builder.run()


if __name__ == "__main__":
    # è¿è¡Œä¸»å‡½æ•°
    main() 